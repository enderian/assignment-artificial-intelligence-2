{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas\n",
    "import re\n",
    "from itertools import islice\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_message(file):\n",
    "    f = open(file)\n",
    "    while True:\n",
    "        if f.readline().strip() == '':\n",
    "            break\n",
    "\n",
    "    return list(map(lambda w: w.strip().lower(), f.read().split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(ratio = 1.0):\n",
    "    spam = glob.glob('email/spam/GP/**/*.eml')\n",
    "    spam_messages = list(map(prepare_message, spam))\n",
    "    ham = glob.glob('email/ham/**/**/*')\n",
    "    ham_messages = list(map(prepare_message, ham))\n",
    "    total_count = len(ham_messages + spam_messages) / ratio\n",
    "    \n",
    "    return total_count, list(islice(spam_messages, int(len(spam_messages) * ratio))), list(islice(ham_messages, int(len(ham_messages) * ratio)))\n",
    "\n",
    "def load_test_datasets():\n",
    "    spam = glob.glob('test/spam/GP/**/*.eml')\n",
    "    spam_messages = list(map(prepare_message, spam))\n",
    "    ham = glob.glob('test/ham/**/**/*')\n",
    "    ham_messages = list(map(prepare_message, ham))\n",
    "    \n",
    "    return spam_messages, ham_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "def segment(message):\n",
    "    words = []\n",
    "    for line in message:\n",
    "        for word in striphtml(line).split(' '):\n",
    "            if word.strip() != '':\n",
    "                words.append(word)\n",
    "    return words\n",
    "\n",
    "def occurance(messages):\n",
    "    occur = defaultdict(int)\n",
    "    for message in messages:\n",
    "        words = set()\n",
    "        for word in segment(message):\n",
    "            words.add(word)\n",
    "        for word in words:\n",
    "            if not word in occur:\n",
    "                occur[word] = 1\n",
    "            occur[word] += 1\n",
    "    return occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(ratio = 1.0):\n",
    "    total_count, spam_messages, ham_messages = load_datasets(ratio)\n",
    "    spam_words = occurance(spam_messages)\n",
    "    ham_words = occurance(ham_messages)\n",
    "    all_words = occurance(ham_messages + spam_messages)\n",
    "    \n",
    "    p_C1 = len(spam_messages) / total_count\n",
    "    pX = {k: v / total_count for k, v in all_words.items()}\n",
    "    pXC0, pXC1 = defaultdict(lambda:1), defaultdict(lambda:1)\n",
    "\n",
    "    for k, v in all_words.items():\n",
    "        if k in ham_words:\n",
    "            pXC0[k] = ham_words[k] / all_words[k]\n",
    "        if k in spam_words:\n",
    "            pXC1[k] = spam_words[k] / all_words[k]\n",
    "\n",
    "    return p_C1, pX, pXC0, pXC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(xi):\n",
    "    pc0 = pc1 = 1\n",
    "    for x in xi:\n",
    "        pc0 = pc0 * pXC0[x]\n",
    "        pc1 = pc1 * pXC1[x]\n",
    "    return p_C0 * pc0, p_C1 * pc1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5388249545729861"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_C1, pX, pXC0, pXC1 = train_naive_bayes(1)\n",
    "p_C0 = 1 - p_C1\n",
    "p_C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9906928645294726, 0.7703045685279187)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_test, ham_test = load_test_datasets()\n",
    "spam_positive = spam_false_positive = 0\n",
    "\n",
    "for message in spam_test:\n",
    "    ham, spam = naive_bayes(message)\n",
    "    if spam > ham:\n",
    "        spam_positive = spam_positive + 1\n",
    "\n",
    "for message in ham_test:\n",
    "    ham, spam = naive_bayes(message)\n",
    "    if spam > ham:\n",
    "        spam_false_positive = spam_false_positive + 1\n",
    "\n",
    "spam_positive / len(spam_test), spam_false_positive / len(ham_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
